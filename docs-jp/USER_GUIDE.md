# MP Ukagaka ユーザーガイド

> 🎭 WordPress サイトにかわいい伺かを追加しよう

---

## 📑 目次

1. [はじめに](#はじめに)
2. [インストールと有効化](#インストールと有効化)
3. [クイックスタート](#クイックスタート)
4. [基本設定](#基本設定)
5. [伺か管理](#伺か管理)
6. [会話設定](#会話設定)
7. [AI 機能設定](#ai-機能設定)
8. [LLM 機能設定（テスト段階）](#llm-機能設定テスト段階)
9. [拡張機能](#拡張機能)
10. [よくある質問](#よくある質問)

---

## はじめに

MP Ukagaka は WordPress プラグインで、サイトにインタラクティブなデスクトップマスコットキャラクター（伺か）を表示できます。キャラクターはカスタムダイアログメッセージを表示でき、AI インテリジェントページ感知機能をサポートし、記事内容に基づいて自動的にコメントを生成します。

> 🎉 **特別なお知らせ**：『葬送のフリーレン』第2期が2026年1月16日に放送開始することを記念して、デフォルトキャラクターを初音からフリーレン（フリーレン）に変更しました。新規インストールユーザーはフリーレンがデフォルトキャラクターとして表示されます。既存ユーザーでデフォルトキャラクター名が「初音」のままの場合、システムが自動的にフリーレンに更新します。

### 主な機能

- 🎨 **複数キャラクターサポート**：複数の伺かキャラクターを作成・管理
- 💬 **カスタムダイアログ**：各キャラクターに専用のダイアログ内容を設定
- 🤖 **汎用 LLM インターフェース**：Ollama、Gemini、OpenAI、Claude の 4 大 AI サービスをサポート
- 🧠 **AI ページ感知**：記事内容に基づいて自動的にコメントを生成
- 🌍 **多言語**：繁体字中国語、日本語、英語をサポート
- 📁 **外部ダイアログファイル**：TXT と JSON 形式のダイアログファイルをサポート
- ⚙️ **高度にカスタマイズ可能**：タイプ速度、表示位置、スタイルなどを調整可能
- 🎭 **カスタムプロンプトシステム**：Markdown/XML 形式の System Prompt をサポート、構造化されたキャラクター設定

---

## インストールと有効化

### システム要件

- WordPress 5.0 以上
- PHP 7.4 以上
- JavaScript をサポートするモダンブラウザ

### インストール手順

1. プラグイン ZIP ファイルをダウンロード
2. WordPress 管理画面にログイン → **プラグイン** → **新規追加**
3. 「プラグインをアップロード」をクリック、ダウンロードした ZIP ファイルを選択
4. 「今すぐインストール」をクリック
5. インストール完了後、「プラグインを有効化」をクリック

### 初期設定

有効化後、**設定** → **MP Ukagaka** で設定を行います。

---

## クイックスタート

### 5 分でクイック設定

1. **設定ページに移動**

   - WordPress 管理画面 → 設定 → MP Ukagaka

2. **デフォルト伺かを確認**

   - 「通用設定」ページで「デフォルト伺か」が選択されていることを確認
   - 「デフォルトで伺かを表示」と「デフォルトで吹き出しを表示」にチェック

3. **設定を保存**

   - 「保存」ボタンをクリック

4. **効果を確認**
   - サイトのフロントエンドに移動し、ページ右下に伺かキャラクターが表示されるはず

---

## 基本設定

**設定** → **MP Ukagaka** → **通用設定** に移動

### 表示設定

| 設定項目 | 説明 |
| -------- | ---- |
| デフォルト伺か | デフォルトで表示するキャラクターを選択 |
| デフォルトで伺かを表示 | デフォルトでキャラクター画像を表示するかどうか |
| デフォルトで吹き出しを表示 | デフォルトで吹き出しを表示するかどうか |

### ダイアログ設定

| 設定項目 | 説明 |
| -------- | ---- |
| デフォルト会話 | 「ランダム」または「最初の一つ」 |
| 会話順序 | クリック時の次の会話は「順序」または「ランダム」 |
| 伺かをクリック | キャラクタークリック時の動作（次を表示または何もしない） |

### 自動ダイアログ

| 設定項目 | 説明 |
| ---------------- | ---------------------------------- |
| 自動ダイアログ機能を有効化 | 自動的にダイアログを切り替えるかどうか |
| 自動ダイアログ間隔 | 自動切り替えの間隔（3-30 秒） |
| タイプ効果速度 | ダイアログのタイプアニメーション速度（10-200 ミリ秒/文字） |

### 外部ダイアログファイル

| 設定項目 | 説明 |
| ---------------- | -------------------------------- |
| 外部ダイアログファイル形式 | TXT または JSON 形式を選択 |
| 外部ダイアログファイルを使用 | `dialogs/` フォルダからダイアログを読み込むかどうか |

### ページ除外

「以下のページで伺かを表示しない」テキストボックスに、伺かを表示したくないページの URL を入力、1 行に 1 つ。

あいまいマッチをサポート：URL の末尾に `(*)` を追加すると、すべてのサブページにマッチ。

**例：**

```
/admin/
/wp-admin/(*)
/private-page/
```

---

## 伺か管理

### 既存の伺かを表示

**設定** → **MP Ukagaka** → **伺かたち** に移動

このページでは：

- 作成済みのすべての伺かを表示
- 伺かの名前、画像、ダイアログを編集
- デフォルト以外の伺かを削除
- 表示するかどうかを設定（表示チェックボックス）

### 新しい伺かを作成

**設定** → **MP Ukagaka** → **新しい伺かを作成** に移動

#### 必須フィールド

| フィールド | 説明 | 例 |
| ---- | ------------------ | --------------------------------- |
| 名前 | 伺かの名前 | `フリーレン` |
| 画像 | 伺か画像の完全 URL | `https://example.com/ukagaka.png` |
| ダイアログ | ダイアログ内容、1 行に 1 つ | 下記の例を参照 |

#### ダイアログ内容例

```
私のサイトへようこそ！
今日はいい天気だね〜
最新の記事を見てみる？
魔法は時間をかけて研究するものだ。
```

#### オプションフィールド

| フィールド | 説明 |
| ------------ | -------------------------------- |
| ダイアログファイル名 | 外部ダイアログファイルの名前（拡張子なし） |
| ダイアログファイルを生成 | チェックすると対応するダイアログファイルを自動生成 |

### 外部ダイアログファイル形式

#### TXT 形式

ファイル場所：`wp-content/plugins/mp-ukagaka/dialogs/キャラクター名.txt`

```
最初のダイアログ

2番目のダイアログ

3番目のダイアログ
```

> ⚠️ 各ダイアログは**空行**で区切る

#### JSON 形式

ファイル場所：`wp-content/plugins/mp-ukagaka/dialogs/キャラクター名.json`

```json
{
  "messages": ["最初のダイアログ", "2番目のダイアログ", "3番目のダイアログ"]
}
```

---

## 会話設定

**設定** → **MP Ukagaka** → **会話** に移動

### 固定メッセージ

このメッセージは**各ダイアログの後に追加**されます。

**使用シーン：**

- サイトからのお知らせを表示
- 署名やスローガンを追加

**例：**

```
—— サイトの RSS を購読してね
```

### 共通会話

入力すると、**すべての伺かがこれらのダイアログを使用**し、各自のカスタムダイアログを置き換えます。

このフィールドをクリアすると、各伺かのデフォルトダイアログに戻ります。

---

## AI 機能設定（ページ感知）

> 💡 **重要なお知らせ**：AI 設定ページは現在「ページ感知」機能専用です。LLM 関連の設定は **LLM 設定** ページに移動してください。

**設定** → **MP Ukagaka** → **AI 設定** に移動

### ページ感知機能とは？

ページ感知機能により、伺かは特定のページ（単一記事、固定ページなど）で記事内容に関連する AI コメントを自動生成できます。この機能を使用するには、まず **LLM 設定** ページで：

1. AI プロバイダーを選択（Gemini、OpenAI、Claude または Ollama）
2. API Key を設定（Ollama 以外）
3. モデルを選択
4. **「ページ認識機能」を有効化**

### 基本設定

#### 1. 言語設定

AI 応答の言語を選択：

- 繁体字中国語
- 日本語
- 英語

#### 2. キャラクター設定（System Prompt）

これはキャラクターのコア性格設定で、System Prompt のコア部分として LLM に送信されます。ここでキャラクターの性格、話し方のスタイルなどを設定できます。

**サポート形式：**

- **プレーンテキスト形式**（基本）：直接テキスト説明を入力
- **Markdown 形式**（推奨）：見出し、リスト、強調などの構造化形式を使用、モデルがより理解しやすい
- **XML タグ形式**（上級）：XML タグで構造をマーク、より細かい制御を提供

**プレーンテキスト例：**

```
あなたは魔法使いフリーレン。話し方は落ち着いていて、やや冷たい感じ。魔法関連の話題には興味を示す。回答は50文字以内に。
```

**Markdown 形式例：**

```markdown
## キャラクター
あなたは魔法使いフリーレン。

## 性格
- 話し方は落ち着いていて、やや冷たい
- 魔法関連の話題に興味を示す
- 時間の感覚が人間と異なる

## 会話ルール
- 回答は50文字以内に
- 常体で話す（敬語は使わない）
```

**XML 形式例：**

```xml
<role>魔法使いフリーレン</role>
<personality>
  <trait>話し方は落ち着いていて、やや冷たい</trait>
  <interest>魔法関連の話題</interest>
</personality>
<rules>
  <response_length>50文字以内</response_length>
  <tone>常体（敬語は使わない）</tone>
</rules>
```

**変数サポート：**

`{{変数名}}` を使用して動的置換が可能、例：

- `{{ukagaka_display_name}}`：キャラクター名
- `{{language}}`：応答言語
- `{{time_context}}`：時間コンテキスト（「春の朝」など）

#### 3. ページ感知確率（%）

条件に合うページで AI コメントをトリガーする確率を設定（1-100%）。

**推奨値：**

- 10-30%：より自然で、頻繁すぎない
- 50%：バランスの取れたトリガー頻度
- 80-100%：ほぼ毎回トリガー

#### 4. トリガーページ

どのページタイプで AI コメントをトリガーするかを設定：

- `is_single`：単一記事
- `is_page`：固定ページ
- `is_home`：ホームページ
- `is_front_page`：静的フロントページ
- `is_archive`：すべてのアーカイブページ
- `is_category`：カテゴリページ
- `is_tag`：タグページ

**例：**

```
is_single,is_page
```

> 💡 **ヒント**：複数条件はカンマで区切ります。

#### 5. AI 会話の表示時間（秒）

AI が生成したコメントがどれくらい表示されてから自動的に消えるかを設定。

**推奨値：**

- 5-10 秒：短い表示時間、読書を邪魔しすぎない
- 10-15 秒：バランスの取れた表示時間
- 15-20 秒：長い表示時間、長いコメントに適している

#### 6. 初回訪問者への挨拶を有効化

このオプションを有効にすると、サイトを初めて訪問した訪問者に特別な挨拶メッセージが表示されます。

#### 7. 初回訪問者挨拶プロンプト

初回訪問者への挨拶メッセージのプロンプトを設定。このプロンプトは「キャラクター設定」と組み合わせて、パーソナライズされた挨拶を生成します。

---

## LLM 機能設定

> 💡 **重要な更新**：LLM 機能が**汎用 LLM インターフェース**にアップグレードされ、複数の AI プロバイダーをサポート！

**設定** → **MP Ukagaka** → **LLM 設定** に移動

### LLM 機能とは？

LLM（Large Language Model）機能により、複数の AI サービスを使用してダイアログを生成できます：

- **Ollama**（ローカル/リモート）：完全無料、API Key 不要
- **Google Gemini**：API Key が必要
- **OpenAI**：API Key が必要
- **Claude (Anthropic)**：API Key が必要

すべてのプロバイダーで統一された設定インターフェースを使用し、いつでも異なる AI サービスに切り替えられます。

### 基本設定

#### 1. AI プロバイダーを選択

**LLM 設定** ページで、以下の AI プロバイダーのいずれかを選択できます：

**Ollama（ローカル/リモート）：**

- 完全無料、API Key 不要
- Ollama をインストールしてモデルをダウンロードする必要あり
- ローカルとリモート接続をサポート

**Google Gemini：**

- API Key が必要（[Google AI Studio](https://makersuite.google.com/app/apikey) から取得）
- 複数モデルをサポート：Gemini 2.5 Flash（推奨）、Gemini 1.5 Pro など

**OpenAI：**

- API Key が必要（[OpenAI Platform](https://platform.openai.com/api-keys) から取得）
- 複数モデルをサポート：GPT-4.1 Mini、GPT-4o など

**Claude (Anthropic)：**

- API Key が必要（[Anthropic Console](https://console.anthropic.com/) から取得）
- 複数モデルをサポート：Claude Sonnet 4.5、Claude Haiku 4.5、Claude Opus 4.5 など

#### 2. API Key を設定（Gemini、OpenAI、Claude）

1. 対応する **API Key** フィールドに API Key を入力
2. API Key は自動的に暗号化保存され、セキュリティを確保
3. 「接続テスト」ボタンをクリックして API Key が有効か確認

> 💡 **セキュリティのヒント**：API Key は WordPress の暗号化機能で保存され、平文でデータベースに保存されることはありません。

#### 3. モデルを選択

選択した AI プロバイダーに応じて、ドロップダウンから適切なモデルを選択：

- **Gemini**：Gemini 2.5 Flash（推奨、高速で低コスト）
- **OpenAI**：GPT-4.1 Mini（推奨、高速で低コスト）、GPT-4o（より賢い）
- **Claude**：Claude Sonnet 4.5（推奨）、Claude Haiku 4.5（高速）、Claude Opus 4.5（最強）

#### 4. Ollama 専用設定

Ollama を選択した場合、追加設定が必要：

**エンドポイントを設定：**

- **ローカル接続**：`http://localhost:11434`
- **リモート接続**：`https://your-domain.com`（Cloudflare Tunnel またはその他のトンネルサービス）

**モデル名を設定：**

ダウンロード済みのモデル名を入力、例：

- `qwen3:8b`
- `llama3.2`
- `mistral`

> 💡 ターミナルで `ollama list` コマンドを使用してダウンロード済みモデルを確認

**接続テスト：**

「Ollama 接続テスト」ボタンをクリックして接続が正常か確認。

#### 5. Modelfile でキャラクター専用モデルを作成（上級）

Ollama の **Modelfile** を使うと、キャラクター設定をモデルに直接埋め込むことができます。これにより、会話ごとに System Prompt を送信する必要がなくなり、**トークン消費を大幅に削減**し、応答の一貫性が向上します。

##### Modelfile とは？

Modelfile は Ollama のモデル設定ファイルで、Docker の Dockerfile に似ています。以下のことができます：

- ベースモデルの指定
- System Prompt（キャラクター設定）の埋め込み
- 生成パラメータの調整（温度、繰り返しペナルティなど）
- 出力長の制限

##### サンプル Modelfile の使用

このプラグインはフリーレンキャラクターの Modelfile サンプルを提供しています：`frieren_modelfile.txt`

**ステップ 1：Modelfile を準備**

```bash
# サンプル Modelfile を作業ディレクトリにコピー
cp wp-content/plugins/mp-ukagaka/frieren_modelfile.txt ~/frieren_modelfile
```

**ステップ 2：ベースモデルを変更（オプション）**

Modelfile を編集し、最初の `FROM` 行をダウンロード済みのモデルに変更：

```dockerfile
# ダウンロード済みのモデルに変更
FROM gemma3:12b
# または他のモデル：
# FROM qwen3:8b
# FROM llama3.2
# FROM mistral
```

**ステップ 3：カスタムモデルを作成**

```bash
# Modelfile を使用して新しいモデルを作成
ollama create frieren -f ~/frieren_modelfile

# 成功すると以下が表示されます
# success
```

**ステップ 4：モデルをテスト**

```bash
# 会話テスト
ollama run frieren "こんにちは"

# フリーレンの口調で応答するはずです
```

**ステップ 5：プラグインで使用**

**LLM 設定** ページで、モデル名を `frieren`（または作成したモデル名）に設定します。

##### Modelfile の構造

```dockerfile
# ベースモデル（事前にダウンロード必要）
FROM gemma3:12b

# System Prompt（キャラクター設定）
SYSTEM """
あなたは「フリーレン」。以下の人格・記憶・態度・話し方・制約を必ず守ること。
...
"""

# パラメータ調整
PARAMETER num_predict 100      # 最大出力トークン数
PARAMETER num_ctx 8192         # コンテキスト長
PARAMETER temperature 0.7      # 温度（創造性）
PARAMETER top_p 0.9            # Top-p サンプリング
PARAMETER top_k 40             # Top-k サンプリング
PARAMETER repeat_penalty 1.3   # 繰り返しペナルティ
PARAMETER repeat_last_n 64     # 繰り返しチェック範囲
```

##### パラメータ推奨値

| パラメータ | 説明 | 推奨値 |
|-----------|------|--------|
| `num_predict` | 最大出力トークン数 | 100（約 40 字の日本語） |
| `num_ctx` | コンテキスト長 | 8192（System Prompt の完全読み取りを確保） |
| `temperature` | 創造性 | 0.7（一貫性と多様性のバランス） |
| `top_p` | Top-p サンプリング | 0.9（適度な多様性） |
| `repeat_penalty` | 繰り返しペナルティ | 1.3（繰り返し削減） |

##### Modelfile vs バックエンド System Prompt

| 方法 | メリット | デメリット |
|------|----------|------------|
| **Modelfile** | トークン消費なし、応答一貫性 | 変更時にモデル再構築が必要 |
| **バックエンド設定** | いつでも変更可能、柔軟 | 毎回トークン消費 |

> 💡 **推奨**：キャラクター設定が安定している場合は Modelfile を使用。まだキャラクターを調整中の場合はバックエンド設定を使用。

##### よく使う Modelfile コマンド

```bash
# 作成したモデルを一覧表示
ollama list

# カスタムモデルを削除
ollama rm frieren

# モデルを再構築（Modelfile 変更後）
ollama rm frieren && ollama create frieren -f ~/frieren_modelfile

# モデル情報を表示
ollama show frieren
```

### 詳細設定

#### LLM で内蔵ダイアログを置換

このオプションを有効にすると：

- すべての伺かダイアログが LLM によってリアルタイム生成
- デフォルトの静的ダイアログリストは使用されない

> 💡 **ヒント**：この機能は「ページ感知」と同時に有効化できます。ページ感知条件に合う場合は AI が記事をコメント、それ以外はランダム生成されたダイアログを使用。

#### 思考モードを無効化（Qwen3、DeepSeek などのモデル）

このオプションを有効にすると：

- Qwen3、DeepSeek などのモデルの思考行動を無効化
- 応答効率が向上
- 応答時間が短縮

**推奨：** Qwen3、DeepSeek または類似モデルを使用する場合、このオプションを有効にすることを推奨。

#### ページ認識機能

この機能は「ページ感知」機能のスイッチを制御します。有効にすると：

- 条件に合うページ（単一記事、固定ページなど）で AI コメントをトリガー
- **AI 設定** ページの「ページ感知確率」でトリガー確率を制御
- 「LLM で内蔵ダイアログを置換」と同時に有効化可能

---

## 拡張機能

**設定** → **MP Ukagaka** → **拡張** に移動

### JS エリア

カスタム JavaScript コードを追加して、伺かにさらに多くのインタラクション機能を追加できます。

**例：伺かをダブルクリックして指定ページにジャンプ**

```javascript
document
  .getElementById("cur_ukagaka")
  .addEventListener("dblclick", function () {
    window.location.href = "/about/";
  });
```

### 特殊コード

ダイアログ内で特殊コードを使用して動的コンテンツを表示できます：

| コード | 説明 |
| ----------------- | --------------------- |
| `:recentpost[5]:` | 最近の 5 記事リストを表示 |
| `:randompost[3]:` | ランダムな 3 記事を表示 |
| `:commenters[5]:` | 最近の 5 人のコメント者を表示 |

**ダイアログ例：**

```
最近の記事：:recentpost[3]:
```

---

## よくある質問

### 伺かが表示されない

1. 「デフォルトで伺かを表示」にチェックが入っているか確認
2. 現在のページが除外リストに入っていないか確認
3. ブラウザキャッシュをクリア
4. JavaScript エラーがないか確認（F12 でコンソールを表示）

### AI がトリガーされない

1. 「ページ感知機能」が有効になっているか確認
2. API Key が正しいか確認
3. 現在のページがトリガー条件に合っているか確認
4. 「AI 応答確率」を一時的に 100% に設定してテスト
5. 記事内容が 500 文字を超えているか確認

### ダイアログが正しく表示されない

1. ダイアログファイル形式が正しいか確認
2. TXT 形式：各ダイアログは**空行**で区切る
3. JSON 形式：有効な JSON であることを確認

### AI 応答が遅い

1. より高速なモデルに切り替えてみる（例：`gemini-2.5-flash`）
2. **クラウド AI サービス**：人格設定（System Prompt）を短くすると API 処理時間が短縮
3. **ローカル LLM**：Prompt の長さは応答速度にあまり影響しない、モデルサイズやハードウェア構成の調整を優先
4. ネットワーク接続を確認

### LLM 接続に失敗

1. **ローカル接続**

   - Ollama サービスが実行中か確認
   - ポートが 11434 か確認
   - ブラウザで `http://localhost:11434` にアクセスしてみる

2. **リモート接続**
   - Cloudflare Tunnel サービスが実行中か確認
   - トンネル URL が正しいか確認
   - ネットワーク接続が正常か確認

### LLM 応答速度が遅い

1. より高速なモデルを使用（例：`qwen3:8b`）
2. 「思考モードを無効化」オプションを有効化
3. リモート接続には追加の遅延がある（正常な現象）

### AI コストを制御するには

1. 「AI 応答確率」を下げる（推奨 10-20%）
2. 「トリガーページ」を制限（`is_single` のみでトリガー）
3. より安価なモデルを使用
4. **または LLM 機能を使用**：完全無料、API Key 不要（テスト段階）

---

## テクニカルサポート

問題がある場合は：

1. 本ユーザーガイドを参照
2. [よくある質問](#よくある質問) セクションを確認
3. [萌えログ.COM](https://www.moelog.com/) を訪問

---

**Made with ❤ for WordPress**
