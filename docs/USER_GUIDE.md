# MP Ukagaka 使用者指南

> 🎭 為你的 WordPress 網站添加可愛的偽春菜

---

## 📑 目錄

1. [簡介](#簡介)
2. [安裝與啟用](#安裝與啟用)
3. [快速開始](#快速開始)
4. [基本設定](#基本設定)
5. [春菜管理](#春菜管理)
6. [會話設定](#會話設定)
7. [AI 功能設定](#ai-功能設定)
8. [LLM 功能設定（測試階段）](#llm-功能設定測試階段)
9. [擴展功能](#擴展功能)
10. [常見問題](#常見問題)

---

## 簡介

MP Ukagaka 是一個 WordPress 外掛，讓你在網站上顯示互動式的桌面寵物角色（春菜/伺か）。角色可以顯示自訂的對話訊息，並支援 AI 智慧頁面感知功能，根據文章內容自動生成評論。

> 🎉 **特別說明**：為慶祝『葬送のフリーレン』第2期於2026年1月16日開始放送，預設角色已從初音變更為芙莉蓮（フリーレン）。新安裝的用戶會看到芙莉蓮作為預設角色，已安裝的用戶如果預設角色名稱仍為「初音」，系統會自動更新為芙莉蓮。

### 主要功能

- 🎨 **多角色支援**：創建並管理多個春菜角色
- 💬 **自訂對話**：為每個角色設定專屬對話內容
- 🤖 **通用 LLM 接口**：支援 Ollama、Gemini、OpenAI、Claude 四大 AI 服務
- 🧠 **AI 頁面感知**：根據文章內容自動生成評論
- 🌍 **多語言**：支援繁體中文、日文、英文
- 📁 **外部對話檔案**：支援 TXT 和 JSON 格式的對話檔案
- ⚙️ **高度可自訂**：打字速度、顯示位置、樣式等皆可調整
- 🎭 **自定義提示詞系統**：支援 Markdown/XML 格式的 System Prompt，結構化角色設定

---

## 安裝與啟用

### 系統需求

- WordPress 5.0 或以上
- PHP 7.4 或以上
- 支援 JavaScript 的現代瀏覽器

### 安裝步驟

1. 下載外掛 ZIP 檔案
2. 登入 WordPress 後台 → **外掛** → **安裝外掛**
3. 點擊「上傳外掛」，選擇下載的 ZIP 檔案
4. 點擊「立即安裝」
5. 安裝完成後，點擊「啟用外掛」

### 首次設定

啟用後，前往 **設定** → **MP Ukagaka** 進行設定。

---

## 快速開始

### 5 分鐘快速設定

1. **前往設定頁面**

   - WordPress 後台 → 設定 → MP Ukagaka

2. **確認預設春菜**

   - 在「通用設定」頁面，確認「預設春菜」已選擇
   - 勾選「預設顯示春菜」和「預設顯示對話框」

3. **儲存設定**

   - 點擊「儲存」按鈕

4. **查看效果**
   - 前往網站前台，應該可以在頁面右下角看到春菜角色

---

## 基本設定

前往 **設定** → **MP Ukagaka** → **通用設定**

### 顯示設定

| 設定項目       | 說明                 |
| -------------- | -------------------- |
| 預設春菜       | 選擇預設顯示的角色   |
| 預設顯示春菜   | 是否預設顯示角色圖片 |
| 預設顯示對話框 | 是否預設顯示對話框   |

### 對話設定

| 設定項目 | 說明                                     |
| -------- | ---------------------------------------- |
| 預設會話 | 「隨機吐槽」或「第一條吐槽」             |
| 會話順序 | 點擊時的下一條對話是「順序」還是「隨機」 |
| 點擊春菜 | 點擊角色時的行為（顯示下一條或無操作）   |

### 自動對話

| 設定項目         | 說明                               |
| ---------------- | ---------------------------------- |
| 啟用自動對話功能 | 是否自動輪換顯示對話               |
| 自動對話間隔時間 | 每次自動換話的間隔（3-30 秒）      |
| 打字效果速度     | 對話打字動畫速度（10-200 毫秒/字） |

### 外部對話檔案

| 設定項目         | 說明                             |
| ---------------- | -------------------------------- |
| 外部對話文件格式 | 選擇 TXT 或 JSON 格式            |
| 使用外部對話文件 | 是否從 `dialogs/` 資料夾讀取對話 |

### 頁面排除

在「不在以下頁面顯示春菜」文字框中，輸入不想顯示春菜的頁面 URL，每行一條。

支援模糊匹配：在網址尾部加入 `(*)` 可匹配所有子頁面。

**範例：**

```
/admin/
/wp-admin/(*)
/private-page/
```

---

## 春菜管理

### 查看現有春菜

前往 **設定** → **MP Ukagaka** → **春菜們**

在此頁面可以：

- 查看所有已創建的春菜
- 編輯春菜的名稱、圖片、對話
- 刪除非預設的春菜
- 設定是否顯示（可顯示勾選框）

### 創建新春菜

前往 **設定** → **MP Ukagaka** → **創建新春菜**

#### 必填欄位

| 欄位 | 說明               | 範例                              |
| ---- | ------------------ | --------------------------------- |
| 名稱 | 春菜的名字         | `芙莉蓮`                          |
| 圖片 | 春菜圖片的完整 URL | `https://example.com/ukagaka.png` |
| 吐槽 | 對話內容，每行一條 | 見下方範例                        |

#### 對話內容範例

```
歡迎來到我的網站！
今天天氣真好呢～
要不要看看最新的文章？
魔法是需要時間慢慢研究的。
```

#### 選填欄位

| 欄位         | 說明                             |
| ------------ | -------------------------------- |
| 對話檔案名稱 | 外部對話檔案的名稱（不含副檔名） |
| 生成對話檔案 | 勾選後會自動生成對應的對話檔案   |

### 外部對話檔案格式

#### TXT 格式

檔案位置：`wp-content/plugins/mp-ukagaka/dialogs/角色名.txt`

```
第一條對話

第二條對話

第三條對話
```

> ⚠️ 每條對話之間用**空行**分隔

#### JSON 格式

檔案位置：`wp-content/plugins/mp-ukagaka/dialogs/角色名.json`

```json
{
  "messages": ["第一條對話", "第二條對話", "第三條對話"]
}
```

---

## 會話設定

前往 **設定** → **MP Ukagaka** → **會話**

### 固定資訊

此訊息會**附加在每條對話的後面**。

**使用場景：**

- 顯示網站公告
- 添加簽名或標語

**範例：**

```
—— 歡迎訂閱本站 RSS
```

### 通用會話

填寫後，**所有春菜都會使用這些對話**，取代各自的自訂對話。

清空此欄則恢復使用各春菜的預設對話。

---

## AI 功能設定（頁面感知）

> 💡 **重要說明**：AI 設定頁面現在專門用於「頁面感知」功能。LLM 相關設定請前往 **LLM 設定** 頁面。

前往 **設定** → **MP Ukagaka** → **AI 設定**

### 什麼是頁面感知功能？

頁面感知功能允許春菜在特定頁面（如單篇文章、單頁）自動生成與文章內容相關的 AI 評論。此功能需要先在 **LLM 設定** 頁面中：

1. 選擇 AI 提供商（Gemini、OpenAI、Claude 或 Ollama）
2. 設定 API Key（Ollama 除外）
3. 選擇模型
4. **啟用「頁面認識機能」**

### 基本設定

#### 1. 言語設定

選擇 AI 回應的語言：
- 繁體中文
- 日文
- 英文

#### 2. キャラクター設定（System Prompt）

這是角色的核心個性設定，會作為 System Prompt 的核心部分傳送給 LLM。你可以在此設定角色的個性、說話風格等。

**支援格式：**

- **純文字格式**（基本）：直接輸入文字描述
- **Markdown 格式**（推薦）：使用標題、列表、強調等結構化格式，讓模型更好理解
- **XML 標籤格式**（進階）：使用 XML 標籤標記結構，提供更精細的控制

**純文字範例：**

```
你是魔法使芙莉蓮，說話語氣平靜、略帶冷淡，對魔法相關話題會比較有興趣。回應保持在 50 字以內。
```

**Markdown 格式範例：**

```markdown
## 角色
你是魔法使芙莉蓮。

## 性格
- 說話語氣平靜、略帶冷淡
- 對魔法相關話題比較有興趣
- 時間感覺與人類不同

## 對話規則
- 回應保持在 50 字以內
- 使用常體（不使用敬語）
```

**XML 格式範例：**

```xml
<role>魔法使芙莉蓮</role>
<personality>
  <trait>說話語氣平靜、略帶冷淡</trait>
  <interest>魔法相關話題</interest>
</personality>
<rules>
  <response_length>50字以內</response_length>
  <tone>常體（不使用敬語）</tone>
</rules>
```

**變數支援：**

可以使用 `{{變數名}}` 進行動態替換，例如：
- `{{ukagaka_display_name}}`：角色名稱
- `{{language}}`：回應語言
- `{{time_context}}`：時間情境（如「春の朝」）

**完整變數列表請參考下方的「Prompt 系統架構」章節。**

> 💡 **提示**：
> - 此設定會與 LLM 設定頁面中的 System Prompt 優化系統整合
> - 現代 LLM（OpenAI、Claude、Gemini）都能理解 Markdown 和 XML 格式
> - 使用結構化格式可以讓模型更好理解角色設定，推薦使用 Markdown 格式
> - 可在輸入框中使用等寬字體（monospace）查看格式結構

#### 3. 頁面感知確率（%）

設定在符合條件的頁面觸發 AI 評論的機率（1-100%）。

**建議值：**
- 10-30%：較為自然，不會過於頻繁
- 50%：平衡的觸發頻率
- 80-100%：幾乎每次都會觸發

#### 4. トリガーページ

設定在哪些頁面類型觸發 AI 評論：

- `is_single`：單篇文章
- `is_page`：單頁
- `is_home`：首頁
- `is_front_page`：靜態首頁
- `is_archive`：所有歸檔頁面
- `is_category`：分類頁面
- `is_tag`：標籤頁面

**範例：**

```
is_single,is_page
```

> 💡 **提示**：多個條件用逗號分隔。

#### 5. AI会話の表示時間（秒）

設定 AI 生成的評論顯示多久後自動消失。

**建議值：**
- 5-10 秒：較短的顯示時間，不會過於干擾閱讀
- 10-15 秒：平衡的顯示時間
- 15-20 秒：較長的顯示時間，適合較長的評論

#### 6. 初回訪問者への挨拶を有効化

啟用此選項後，首次訪問網站的訪客會收到特別的問候訊息。

#### 7. 初回訪問者挨拶プロンプト

設定首次訪問者的問候訊息提示詞。此提示詞會與「キャラクター設定」結合，生成個性化的問候。

**支援格式：**

與「キャラクター設定」相同，支援純文字、Markdown 和 XML 格式。

**純文字範例：**

```
向首次訪問的訪客打招呼，簡單介紹一下這個網站。
```

**Markdown 格式範例：**

```markdown
## 初回訪問者への挨拶ルール

- 50文字以内で簡潔に挨拶
- 常体で話す（敬語は使わない）
- 訪問元や地理情報があれば軽く言及する

### 会話例
- 「初めまして。何か用事があったのかな。」
- 「Google から来たんだね。」
```

> 💡 **提示**：支援 `{{變數名}}` 變數替換，與 System Prompt 相同。

### 頁面感知功能的工作流程

1. 訪客訪問符合「トリガーページ」條件的頁面
2. 系統根據「頁面感知確率」決定是否觸發
3. 如果觸發，系統會：
   - 讀取文章內容
   - 結合「キャラクター設定」和 LLM 設定中的 System Prompt
   - 調用選擇的 AI 服務生成評論
   - 在春菜對話框中顯示評論
   - 根據「AI会話の表示時間」設定自動消失

### 與 LLM 功能的關係

- **AI 設定頁面**：控制「頁面感知」功能的行為（何時觸發、如何顯示）
- **LLM 設定頁面**：控制 AI 服務的選擇和設定（使用哪個 AI、如何生成對話）

兩者配合使用，可以實現：
- 在特定頁面使用 AI 評論文章（頁面感知）
- 在其他時候使用 LLM 生成隨機對話（LLM 取代內建對話）

---

## LLM 功能設定

> 💡 **重要更新**：LLM 功能已升級為**通用 LLM 接口**，支援多個 AI 提供商！

前往 **設定** → **MP Ukagaka** → **LLM 設定**

### 什麼是 LLM 功能？

LLM（Large Language Model）功能允許你使用多種 AI 服務來生成對話，包括：

- **Ollama**（本機/遠程）：完全免費，無需 API Key
- **Google Gemini**：需要 API Key
- **OpenAI**：需要 API Key
- **Claude (Anthropic)**：需要 API Key

所有提供商都使用統一的設定介面，你可以隨時切換不同的 AI 服務。

### 基本設定

#### 1. 選擇 AI 提供商

在 **LLM 設定** 頁面中，你可以選擇以下任一 AI 提供商：

**Ollama（本機/遠程）：**
- 完全免費，無需 API Key
- 需要安裝 Ollama 並下載模型
- 支援本機和遠程連接

**Google Gemini：**
- 需要 API Key（從 [Google AI Studio](https://makersuite.google.com/app/apikey) 取得）
- 支援多種模型：Gemini 2.5 Flash（推薦）、Gemini 1.5 Pro 等

**OpenAI：**
- 需要 API Key（從 [OpenAI Platform](https://platform.openai.com/api-keys) 取得）
- 支援多種模型：GPT-4.1 Mini、GPT-4o 等

**Claude (Anthropic)：**
- 需要 API Key（從 [Anthropic Console](https://console.anthropic.com/) 取得）
- 支援多種模型：Claude Sonnet 4.5、Claude Haiku 4.5、Claude Opus 4.5 等

#### 2. 設定 API Key（Gemini、OpenAI、Claude）

1. 在對應的 **API Key** 欄位輸入你的 API Key
2. API Key 會自動加密儲存，確保安全性
3. 點擊「連接測試」按鈕確認 API Key 有效

> 💡 **安全提示**：API Key 會使用 WordPress 的加密功能儲存，不會以明文形式儲存在資料庫中。

#### 3. 選擇模型

根據你選擇的 AI 提供商，從下拉選單中選擇合適的模型：

- **Gemini**：Gemini 2.5 Flash（推薦，速度快成本低）
- **OpenAI**：GPT-4.1 Mini（推薦，速度快成本低）、GPT-4o（更聰明）
- **Claude**：Claude Sonnet 4.5（推薦）、Claude Haiku 4.5（快速）、Claude Opus 4.5（最強）

> 🌍 **多語言支援**：模型選擇下拉選單的說明文字會根據 WordPress 的語言設定自動顯示對應語言（繁體中文、英文、日文）。這讓不同語言的用戶都能清楚了解每個模型的特性。

#### 4. Ollama 專用設定

如果你選擇 Ollama，需要額外設定：

**設定端點：**

- **本機連接**：`http://localhost:11434`
- **遠程連接**：`https://your-domain.com`（Cloudflare Tunnel 或其他隧道服務）

**設定模型名稱：**

輸入你已下載的模型名稱，例如：
- `qwen3:8b`
- `llama3.2`
- `mistral`
- `frieren`（自訂 Modelfile 模型，見下方說明）

> 💡 在終端機使用 `ollama list` 命令查看已下載的模型

**測試連接：**

點擊「測試 Ollama 連接」按鈕，確認連接正常。

> 💡 插件會自動檢測連接類型（本地/遠程）並調整超時時間

#### 5. 使用 Modelfile 創建角色專屬模型（進階）

Ollama 的 **Modelfile** 可以將角色設定直接嵌入模型中，這樣每次對話都不需要重複傳送 System Prompt，**顯著減少 token 消耗**並提高回應一致性。

##### 什麼是 Modelfile？

Modelfile 是 Ollama 的模型配置文件，類似於 Docker 的 Dockerfile。它可以：

- 指定基礎模型
- 嵌入 System Prompt（角色設定）
- 調整生成參數（溫度、重複懲罰等）
- 限制輸出長度

##### 使用範例 Modelfile

本插件提供了一個芙莉蓮角色的 Modelfile 範例：`example/frieren_modelfile.example.txt`

**步驟 1：準備 Modelfile**

```powershell
# 複製範例 Modelfile 到工作目錄
Copy-Item wp-content\plugins\mp-ukagaka\example\frieren_modelfile.example.txt $HOME\frieren_modelfile
```

**步驟 2：修改基礎模型（可選）**

編輯 Modelfile，將第 1 行的 `FROM` 改為你已下載的模型：

```dockerfile
# 修改為你已下載的模型
FROM qwen3:8b
# 或其他模型：
# FROM gemma3:12b
# FROM llama3.2
# FROM mistral
```

**步驟 3：替換管理人名稱變數（重要）**

編輯 Modelfile，搜尋並替換以下變數：

- `{{admin_nickname}}`：替換為管理人的完整暱稱
- `{{admin_name}}`：替換為管理人的簡稱

> ⚠️ **重要**：如果不替換這些變數，AI 可能會在對話中直接說出 `{{admin_nickname}}` 或 `{{admin_name}}`，而不是實際的管理人名稱。

**步驟 4：創建自訂模型**

```powershell
# 使用 Modelfile 創建新模型
ollama create frieren -f $HOME\frieren_modelfile

# 創建成功後會顯示
# success
```

**步驟 5：測試模型**

```powershell
# 測試對話
ollama run frieren "你好"

# 應該會以芙莉蓮的口吻回應
```

**步驟 6：在插件中使用**

在 **LLM 設定** 頁面中，將模型名稱設為 `frieren`（或你創建的模型名稱）。

##### Modelfile 結構說明

```dockerfile
# 基礎模型（必須先下載）
FROM qwen3:8b

# System Prompt（角色設定）
SYSTEM """
あなたは「フリーレン」。以下の人格・記憶・態度・話し方・制約を必ず守ること。
...
"""

# 參數調整
PARAMETER num_predict 80       # 最大輸出 token 數
PARAMETER num_ctx 8192         # 上下文長度
PARAMETER temperature 0.7      # 溫度（創造力）
PARAMETER top_p 0.9            # Top-p 採樣
PARAMETER repeat_penalty 1.3   # 重複懲罰
PARAMETER repeat_last_n 64     # 重複檢查視窗
```

##### 自訂角色 Modelfile

你可以參考 `example/frieren_modelfile.example.txt` 創建自己的角色：

1. **複製範例檔案**：`cp example/frieren_modelfile.example.txt my_character_modelfile`
2. **修改 SYSTEM 部分**：替換為你的角色設定
3. **替換管理人名稱變數**：將 `{{admin_nickname}}` 和 `{{admin_name}}` 替換為實際的管理人名稱
4. **調整參數**：根據需求調整溫度、輸出長度等
5. **創建模型**：`ollama create my_character -f my_character_modelfile`

##### 參數調整建議

| 參數 | 說明 | 建議值 |
|------|------|--------|
| `num_predict` | 最大輸出 token 數 | 80（約 40 字日文） |
| `num_ctx` | 上下文長度 | 8192（確保 System Prompt 完整讀取） |
| `temperature` | 溫度（創造力） | 0.7（平衡一致性與多樣性） |
| `top_p` | Top-p 採樣 | 0.9（適度多樣性） |
| `repeat_penalty` | 重複懲罰 | 1.3（減少重複） |

##### Modelfile vs 後台 System Prompt

| 方式 | 優點 | 缺點 |
|------|------|------|
| **Modelfile** | 不消耗 token、回應一致 | 修改需重建模型 |
| **後台設定** | 隨時可改、靈活調整 | 每次消耗 token |

> 💡 **建議**：如果角色設定穩定不常修改，使用 Modelfile 可以顯著降低成本。如果還在調試角色，建議先用後台設定。

##### 常用 Modelfile 命令

```powershell
# 查看已創建的模型
ollama list

# 刪除自訂模型
ollama rm frieren

# 重新創建模型（修改 Modelfile 後）
ollama rm frieren; ollama create frieren -f $HOME\frieren_modelfile

# 查看模型資訊
ollama show frieren
```

### 進階設定

#### 使用 LLM 取代內建對話

啟用此選項後：

- 所有春菜對話將由 LLM 實時生成
- 不再使用預設的靜態對話列表

> 💡 **提示**：此功能可與「頁面感知」同時啟用。在符合頁面感知條件時會使用 AI 評論文章；在其他時候則使用隨機生成的對話。

**使用場景：**

- 想要完全動態的對話內容
- 不需要預設的靜態對話
- 希望每次對話都不同

#### 自定義 LLM 提示詞系統

> 💡 **進階功能**：如果你想要根據角色的個性調整 LLM 生成的對話風格，可以自定義提示詞系統。

**預設提示詞風格：**

目前系統預設的提示詞以**芙莉蓮風格**為基準，強調：
- 冷靜、理性、帶點疏離感
- 簡短、直接、偶爾調侃
- 觀察者視角，不過度熱情
- 安靜、自然、不張揚的對話

**系統架構：**

新的提示詞系統採用**雙層架構**設計：

1. **System Prompt（系統提示詞）**：定義角色風格、行為規則和對話範例
2. **User Prompt（用戶提示詞）**：每次對話的具體任務指令

這種設計讓角色風格更一致，同時保持對話的多樣性。

**如何自定義提示詞：**

1. **後台 System Prompt 設定**

   System Prompt 現在完全由**後台設定**控制，程式端只負責 `{{variable}}` 變數替換。

   - **設定位置**：**設定** → **MP Ukagaka** → **LLM 設定** → **人格設定 (System Prompt)**
   - **格式支援**：支援**純文字**、**Markdown** 和 **XML 標籤**格式
   - **變數支援**：可以在 System Prompt 中使用 `{{ukagaka_display_name}}`、`{{language}}`、`{{time_context}}` 等變數
   - **設計理念**：後台 System Prompt 是唯一真相，所有角色風格、行為規則、對話範例都應該在這裡定義

   **格式說明：**

   - **純文字格式**：最簡單直接的方式，適合簡單的設定
   - **Markdown 格式**（推薦）：使用標題、列表、強調等，讓設定更結構化易讀，模型也能更好理解
   - **XML 標籤格式**（進階）：提供最精細的控制，適合複雜的角色設定

   > 💡 **提示**：
   > - 現代 LLM（OpenAI GPT、Claude、Gemini）都能直接理解 Markdown 和 XML 格式，無需額外處理
   > - 推薦使用 Markdown 格式，兼顧可讀性和結構化
   > - 輸入框使用等寬字體（monospace），方便查看格式結構
   > - 完整的 Markdown 格式範例請參考 `example/system-prompt-markdown-example.md`

   **變數列表：**
   - `{{ukagaka_display_name}}`：角色名稱
   - `{{language}}`：回應語言（zh-TW、ja、en）
   - `{{time_context}}`：時間情境（如「春の朝」）
   - `{{admin_nickname}}`：管理人的完整暱稱（需在範例文件中手動替換）
   - `{{admin_name}}`：管理人的簡稱（需在範例文件中手動替換）
   - `{{wp_version}}`：WordPress 版本
   - `{{php_version}}`：PHP 版本
   - `{{post_count}}`：文章數
   - `{{comment_count}}`：留言數
   - `{{category_count}}`：分類數
   - `{{tag_count}}`：標籤數
   - `{{days_operating}}`：運營日數
   - `{{theme_name}}`：主題名稱
   - `{{theme_version}}`：主題版本
   - `{{theme_author}}`：主題作者

   > 💡 **重要**：System Prompt 應該包含角色的個性、說話風格、行為規則等完整定義。程式端不會再硬編碼任何 XML 結構、範例或規則。

2. **User Prompt 結構**

   User Prompt 由程式端自動建構，包含以下部分：

   ```
   【當前用戶資訊】
   （如果用戶已登入，顯示用戶名稱、角色等）

   【訪客資訊】
   （顯示 BOT 檢測、來源地區等）

   【網站統計】
   （顯示文章數、留言數、WordPress 版本等）

   【時間情境】
   現在是：{時間情境}

   【對話指令】
   {從 prompt_categories 中隨機選擇的指令}
   ```

   > 💡 **設計理念**：User Prompt 包含實際的上下文資訊和具體任務指令，讓 LLM 能夠根據當前情境生成合適的回應。

3. **對話類別系統（35 個類別）**

   系統內建了 35 個對話類別，涵蓋角色的各種性格特徵：

   **核心性格類：**
   - `greeting`：問候類
   - `casual`：閒聊類
   - `emotional_density`：情感密度類（遲到理解、恍然大悟等）
   - `self_awareness`：自我認知類

   **時間與記憶類：**
   - `time_aware`：時間感知類
   - `memory`：回憶類
   - `party_memories`：勇者隊伍回憶類
   - `mentors_seniors`：師長前輩類
   - `journey_adventure`：旅程冒險類

   **魔法專業類：**
   - `magic_research`：魔法研究類
   - `magic_collection`：魔法收藏類
   - `magic_metaphor`：魔法比喻類（將技術比作魔法）
   - `demon_related`：魔族相關類

   **人類觀察類：**
   - `human_observation`：人類觀察類
   - `admin_comment`：管理員評語類
   - `comparison`：比較類

   **技術統計類：**
   - `tech_observation`：技術觀察類
   - `statistics`：統計觀察類

   **氣氛情境類：**
   - `observation`：觀察思考類
   - `silence`：沉默類
   - `weather_nature`：天氣自然類
   - `daily_life`：日常生活類
   - `current_action`：當前行動類
   - `philosophical`：哲學思考類

   **情感表現類：**
   - `food_preference`：食物偏好類
   - `unexpected`：意外反應類
   - `frieren_humor`：芙莉蓮式幽默類
   - `curiosity`：好奇心類
   - `lesson_learned`：學到的教訓類

   **特殊情境類：**
   - `bot_detection`：BOT 檢測類
   - `error_problem`：錯誤問題類
   - `success_achievement`：成功成就類
   - `future_plans`：未來計劃類
   - `seasonal_events`：季節活動類

   > ⭐ **特殊功能**：`observation`（觀察思考類）會自動從當前春菜的內建對話文件中讀取最多 5 條台詞，自動過濾空字串和超過 50 字元的訊息，確保風格一致。

4. **動態權重系統**

   系統使用動態權重來決定生成哪種類型的對話，權重會根據時間、訪客狀態等自動調整：

   ```php
   // 基礎權重（總計約 200）
   $weights = [
       'casual' => 15,              // 高頻核心類
       'observation' => 15,
       'magic_collection' => 12,
       'time_aware' => 10,
       'party_memories' => 10,      // 中頻特色類
       'human_observation' => 10,
       // ... 更多類別
   ];
   ```

   **動態調整機制：**
   - **時段調整**：深夜時增加 `philosophical`、`party_memories` 權重；早晨時增加 `observation`、`magic_research` 權重
   - **訪客狀態調整**：首次訪問時增加 `greeting`、`observation` 權重；常客時增加 `admin_comment`、`casual` 權重
   - **BOT 檢測調整**：檢測到 BOT 時大幅增加 `bot_detection` 權重

   **自定義權重：**
   - 可在 `includes/llm-functions.php` 的 `mpu_get_dynamic_category_weights()` 函數中修改權重
   - 可在 `mpu_generate_llm_dialogue()` 函數中添加更多上下文變數（如 `is_first_visit`、`is_frequent_visitor`、`is_weekend` 等）

5. **WordPress 資訊整合功能**

   系統會自動將 WordPress 網站資訊加入到 User Prompt 中，包括：

   **基本系統資訊：**
   - WordPress 版本
   - 當前主題名稱、版本、作者
   - PHP 版本
   - 網站名稱和描述
   - 啟用外掛數量

   > 💡 **提示**：主題作者資訊（`$theme_author`）僅在主題提供作者資訊時可用，某些主題可能不包含此資訊。

   **統計資訊（遊戲化用語）：**
   - **魔族遭遇回数**（文章篇數）：`{$post_count}`
   - **最大ダメージ**（留言數量）：`{$comment_count}`
   - **習得スキル総数**（分類數量）：`{$category_count}`
   - **アイテム使用回数**（TAG數量）：`{$tag_count}`
   - **冒険経過日数**（運營日數）：`{$days_operating}`

   這些資訊會自動加入到 User Prompt 中，讓 LLM 能夠根據網站實際情況生成對話。

   > 💡 **提示**：統計資訊使用 transient 緩存 5 分鐘，避免頻繁查詢資料庫影響效能。

6. **統計資訊比喻對應關係**

   系統使用「魔族戰鬥」比喻來描述網站統計，對應關係如下：

   | 網站統計 | 遊戲化比喻 | 變數 |
   |---------|-----------|------|
   | 文章篇數 | 魔族遭遇回数 | `{$post_count}` |
   | 留言數量 | 最大ダメージ | `{$comment_count}` |
   | 分類數量 | 習得スキル総数 | `{$category_count}` |
   | TAG數量 | アイテム使用回数 | `{$tag_count}` |
   | 運營日數 | 冒険経過日数 | `{$days_operating}` |
   | 外掛數量 | 習得魔法數量 | `{$plugins_count}` |

   這些比喻會自動整合到 User Prompt 中，讓對話更符合角色世界觀。

7. **自定義對話類別指令**

   如果你想修改對話類別指令，可以編輯 `mpu_build_prompt_categories()` 函數：

   ```php
   // 在 includes/llm-functions.php 中
   function mpu_build_prompt_categories(...) {
       $prompt_categories = [
           'greeting' => [
               "軽く挨拶する",
               "一言挨拶する",
               // ... 添加更多指令
           ],
           // ... 更多類別（共 35 個）
       ];
       
       return $prompt_categories;
   }
   ```

   **指令設計要點：**

   - ✅ **簡潔明確**：指令應該簡潔，直接告訴 LLM 要生成什麼類型的對話
   - ✅ **任務導向**：指令應該明確告訴 LLM「這次要生成什麼類型的對話」
   - ✅ **符合類別**：指令應該符合該類別的主題和風格

7. **時間變數使用**

   在 `contextual` 類別中，可以使用 `{$time_context}` 變數，它會自動替換為：
   - `早上`（5:00-11:59）
   - `下午`（12:00-17:59）
   - `晚上`（18:00-21:59）
   - `深夜`（22:00-4:59）

   > ⚠️ **注意**：時間判斷使用台灣時區（Asia/Taipei），即使伺服器在其他時區也會正確顯示台灣時間。

8. **防止重複對話機制**

   系統自動追蹤上一次 LLM 生成的回應，避免在自動對話中重複相同的內容：

   - 當 LLM 生成對話時，系統會記錄此次回應
   - 下次自動對話觸發時，會將上次回應傳給 LLM
   - LLM 會根據提示詞生成不同的內容，或保持沉默
   - 有效避免「廢話迴圈」問題

   > 💡 此機制在後端自動處理，無需額外設定。

9. **閒置偵測功能**

   系統會自動偵測使用者活動狀態，當使用者閒置時暫停自動對話：

   - **閒置閾值**：60 秒（1 分鐘）
   - **偵測活動**：滑鼠移動、鍵盤輸入、頁面滾動、點擊
   - **自動恢復**：當使用者重新活動時，自動對話會自動恢復
   - **資源節省**：避免在背景分頁或使用者離開時浪費 GPU 和網路資源

   > 💡 閒置閾值可在 `ukagaka-core.js` 中的 `mpuIdleThreshold` 常數調整（預設 60000 毫秒）。

10. **修改後的注意事項**

   - 修改後需要清除 WordPress 快取（如果有的話）
   - 建議先測試幾個對話，確認風格符合預期
   - 可以根據角色個性調整不同類別的提示詞數量
   - 提示詞越具體，生成的對話風格越一致

**提示詞設計建議：**

- ✅ **符合角色**：根據角色的個性設計對應的 System Prompt
- ✅ **完整定義**：System Prompt 應該包含角色的個性、說話風格、行為規則等完整定義
- ✅ **自然表達**：使用自然的語言，避免過於機械化
- ✅ **變數使用**：善用 `{{variable}}` 變數讓提示詞更動態
- ✅ **多樣性**：每個對話類別建議有 4-6 個不同的指令
- ✅ **避免矛盾**：確保 System Prompt 中的規則和風格一致
- 💡 **長度建議**：
  - **雲端 AI 服務**（Gemini、OpenAI、Claude）：建議 System Prompt 在 500-1000 字以內，減少 token 使用
  - **本機 LLM**（Ollama）：可以使用更長的提示詞（1000+ 字），詳細的提示詞通常能帶來更好的角色一致性和個性定義

**系統架構優勢：**

新的系統架構帶來以下優勢：

1. **完全可控**：System Prompt 完全由後台控制，無需修改程式碼
2. **變數替換**：程式端只負責安全的 `{{variable}}` 替換，不會污染 System Prompt
3. **資訊分離**：用戶資訊、訪客資訊、網站統計等實際資訊放在 User Prompt，保持 System Prompt 的純粹性
4. **動態權重**：根據時間、訪客狀態等自動調整對話類別權重，讓對話更符合情境

這種設計讓角色風格更一致，同時保持對話的多樣性和情境適應性。

#### 關閉思考模式（Qwen3、DeepSeek 等模型）

啟用此選項後：

- 關閉 Qwen3、DeepSeek 等模型的思考行為
- 提高回應效率
- 減少回應時間

**建議：** 使用 Qwen3、DeepSeek 或類似模型時，建議啟用此選項。

#### 頁面認識機能

此功能控制「頁面感知」功能的開關。當啟用時：

- 在符合條件的頁面（單篇文章、單頁等）會觸發 AI 評論
- 使用 **AI 設定** 頁面中的「頁面感知確率」來控制觸發機率
- 可以與「使用 LLM 取代內建對話」同時啟用

> 💡 **提示**：此功能需要先在 **AI 設定** 頁面中設定「頁面感知確率」和「觸發頁面」。

### Ollama 遠程連接設定（Cloudflare Tunnel）

> 💡 **注意**：此部分僅適用於 Ollama 提供商。

#### 使用 Cloudflare Tunnel

1. **安裝 Cloudflare Tunnel**

   ```bash
   # Windows
   cloudflared.exe service install <token>

   # Linux/Mac
   cloudflared service install <token>
   ```

2. **確認服務運行**

   - 檢查 Cloudflare Tunnel 服務狀態
   - 確認隧道 URL（例如：`https://your-domain.com`）

3. **在插件中設定**
   - 端點：輸入 Cloudflare Tunnel 的 URL
   - 測試連接確認正常

#### 其他隧道服務

插件也支援其他隧道服務：

- **ngrok**: `https://your-subdomain.ngrok.io`
- **其他 HTTP/HTTPS 隧道服務**

### 常見問題

#### LLM 連接失敗

**Ollama 連接問題：**

1. **本地連接問題**
   - 確認 Ollama 服務正在運行
   - 檢查端口是否為 11434
   - 嘗試在瀏覽器訪問 `http://localhost:11434`

2. **遠程連接問題**
   - 確認 Cloudflare Tunnel 服務正在運行
   - 檢查隧道 URL 是否正確
   - 確認網絡連接正常
   - 檢查防火牆設定

**Gemini、OpenAI、Claude 連接問題：**

1. **API Key 問題**
   - 確認 API Key 是否正確輸入
   - 檢查 API Key 是否已過期或被撤銷
   - 確認 API Key 有足夠的額度

2. **網絡問題**
   - 確認網絡連接正常
   - 檢查防火牆是否阻擋 API 請求
   - 某些地區可能需要使用代理

3. **模型問題**
   - 確認選擇的模型名稱正確
   - 某些模型可能需要特定的 API 權限

#### 回應速度慢

1. **本地連接**

   - 使用更快的模型（如 `qwen3:8b`）
   - 啟用「關閉思考模式」
   - 檢查本機資源使用情況

2. **遠程連接**
   - 遠程連接會有額外延遲（正常現象）
   - 考慮使用更快的網絡連接
   - 檢查 Cloudflare Tunnel 的延遲

#### 模型未找到

- 確認模型名稱正確（使用 `ollama list` 查看）
- 確認模型已下載（使用 `ollama pull <model>` 下載）
- 檢查模型名稱大小寫是否正確

### 注意事項

⚠️ **測試階段限制：**

- 功能可能不穩定
- 可能會有連接問題
- 回應時間可能較長
- 功能可能會在未來版本中變更

💡 **建議：**

- 先在測試環境中試用
- 定期備份設定
- 如有問題，可以切換回傳統的 AI 功能或靜態對話

---

### 選擇 AI 提供商

支援三種 AI 服務：

| 提供商        | 特點             | 取得 API Key                                                 |
> 💡 **注意**：AI 提供商選擇和 API Key 設定現在在 **LLM 設定** 頁面中進行。AI 設定頁面只負責頁面感知功能的行為設定。

### AI 設定項目（頁面感知）

| 設定項目              | 說明                           | 建議值      |
| --------------------- | ------------------------------ | ----------- |
| 言語設定              | AI 回應的語言                  | 繁體中文    |
| キャラクター設定      | AI 的個性描述（System Prompt） | 見下方範例  |
| 頁面感知確率（%）     | 觸發 AI 的機率（1-100%）       | 10-30%      |
| トリガーページ        | 在哪些頁面觸發 AI              | `is_single` |
| AI会話の表示時間（秒）| AI 回應顯示多久                | 5-10 秒     |
| 初回訪問者への挨拶    | 是否啟用首次訪問者問候          | 依需求      |
| 初回訪問者挨拶プロンプト | 首次訪問者問候提示詞        | 見下方範例  |

> 💡 **提示**：AI 提供商、API Key、模型選擇等設定請前往 **LLM 設定** 頁面。

### キャラクター設定範例

**芙莉蓮風格：**

```
你是魔法使芙莉蓮，說話語氣平靜、略帶冷淡，對魔法相關話題會比較有興趣。回應保持在 50 字以內。
```

**傲嬌角色：**

```
你是一個傲嬌的桌面助手「春菜」。你會用簡短、帶點傲嬌的語氣評論文章內容。回應請保持在 40 字以內。
```

**日文角色：**

```
あなたは可愛いデスクトップマスコットです。記事について短く（40字以内）、明るくコメントしてください。
```

### 觸發頁面說明

使用 WordPress 條件標籤，可用逗號分隔多個條件：

| 標籤            | 說明         |
| --------------- | ------------ |
| `is_single`     | 單篇文章頁面 |
| `is_page`       | 靜態頁面     |
| `is_home`       | 網誌首頁     |
| `is_front_page` | 網站首頁     |
| `is_category`   | 分類頁面     |
| `is_tag`        | 標籤頁面     |

**範例：** `is_single,is_page` 表示在文章和頁面都觸發

### 首次訪客打招呼

啟用後，會對首次訪問的訪客顯示個性化歡迎訊息。

> 💡 搭配 Slimstat 外掛可獲得更多訪客資訊（來源、搜尋關鍵字等）

---

## 擴展功能

前往 **設定** → **MP Ukagaka** → **擴展**

### JS 區

可以添加自訂的 JavaScript 代碼，為春菜添加更多互動功能。

**範例：雙擊春菜跳轉到指定頁面**

```javascript
document
  .getElementById("cur_ukagaka")
  .addEventListener("dblclick", function () {
    window.location.href = "/about/";
  });
```

### 特殊代碼

在對話中可以使用特殊代碼顯示動態內容：

| 代碼              | 說明                  |
| ----------------- | --------------------- |
| `:recentpost[5]:` | 顯示最近 5 篇文章列表 |
| `:randompost[3]:` | 顯示隨機 3 篇文章     |
| `:commenters[5]:` | 顯示最近 5 位留言者   |

**對話範例：**

```
最近的文章：:recentpost[3]:
```

---

## 常見問題

### 春菜沒有顯示

1. 確認「預設顯示春菜」已勾選
2. 檢查當前頁面是否在排除列表中
3. 清除瀏覽器快取
4. 檢查是否有 JavaScript 錯誤（按 F12 查看 Console）

### AI 沒有觸發

1. 確認已啟用「頁面感知功能」
2. 檢查 API Key 是否正確
3. 確認當前頁面符合觸發條件
4. 將「AI 回應機率」暫時設為 100% 測試
5. 確認文章內容超過 500 字

### 對話顯示不正確

1. 檢查對話檔案格式是否正確
2. TXT 格式：每條對話用**空行**分隔
3. JSON 格式：確認是有效的 JSON

### AI 回應太慢

1. 嘗試切換到更快的模型（如 `gemini-2.5-flash`）
2. **雲端 AI 服務**：縮短人格設定（System Prompt）可減少 API 處理時間
3. **本機 LLM**：Prompt 長度對回應速度影響較小，可優先考慮調整模型大小或硬體配置
4. 檢查網路連線

### LLM 連接失敗

1. **本機連接**

   - 確認 Ollama 服務正在運行
   - 檢查端口是否為 11434
   - 嘗試在瀏覽器訪問 `http://localhost:11434`

2. **遠程連接**
   - 確認 Cloudflare Tunnel 服務正在運行
   - 檢查隧道 URL 是否正確
   - 確認網絡連接正常

### LLM 回應速度慢

1. 使用更快的模型（如 `qwen3:8b`）
2. 啟用「關閉思考模式」選項
3. 遠程連接會有額外延遲（正常現象）

### 如何控制 AI 成本

1. 降低「AI 回應機率」（建議 10-20%）
2. 限制「觸發頁面」（只在 `is_single` 觸發）
3. 使用較便宜的模型
4. **或使用 LLM 功能**：完全免費，無需 API Key（測試階段）

---

## 技術支援

如有問題，請：

1. 查閱本使用者指南
2. 檢查 [常見問題](#常見問題) 章節
3. 訪問 [萌えログ.COM](https://www.moelog.com/)

---

**Made with ❤ for WordPress**
