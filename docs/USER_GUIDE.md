# MP Ukagaka 使用者指南

> 🎭 為你的 WordPress 網站添加可愛的桌面寵物（春菜）

---

## 📑 目錄

1. [簡介](#簡介)
2. [安裝與啟用](#安裝與啟用)
3. [快速開始](#快速開始)
4. [基本設定](#基本設定)
5. [春菜管理](#春菜管理)
6. [會話設定](#會話設定)
7. [AI 功能設定](#ai-功能設定)
8. [LLM 功能設定（測試階段）](#llm-功能設定測試階段)
9. [擴展功能](#擴展功能)
10. [常見問題](#常見問題)

---

## 簡介

MP Ukagaka 是一個 WordPress 外掛，讓你在網站上顯示互動式的桌面寵物角色（春菜/伺か）。角色可以顯示自訂的對話訊息，並支援 AI 智慧頁面感知功能，根據文章內容自動生成評論。

### 主要功能

- 🎨 **多角色支援**：創建並管理多個春菜角色
- 💬 **自訂對話**：為每個角色設定專屬對話內容
- 🤖 **AI 頁面感知**：支援 Gemini、OpenAI、Claude 三大 AI 服務
- 🌍 **多語言**：支援繁體中文、日文、英文
- 📁 **外部對話檔案**：支援 TXT 和 JSON 格式的對話檔案
- ⚙️ **高度可自訂**：打字速度、顯示位置、樣式等皆可調整

---

## 安裝與啟用

### 系統需求

- WordPress 5.0 或以上
- PHP 7.4 或以上
- 支援 JavaScript 的現代瀏覽器

### 安裝步驟

1. 下載外掛 ZIP 檔案
2. 登入 WordPress 後台 → **外掛** → **安裝外掛**
3. 點擊「上傳外掛」，選擇下載的 ZIP 檔案
4. 點擊「立即安裝」
5. 安裝完成後，點擊「啟用外掛」

### 首次設定

啟用後，前往 **設定** → **MP Ukagaka** 進行設定。

---

## 快速開始

### 5 分鐘快速設定

1. **前往設定頁面**
   - WordPress 後台 → 設定 → MP Ukagaka

2. **確認預設春菜**
   - 在「通用設定」頁面，確認「預設春菜」已選擇
   - 勾選「預設顯示春菜」和「預設顯示對話框」

3. **儲存設定**
   - 點擊「儲存」按鈕

4. **查看效果**
   - 前往網站前台，應該可以在頁面右下角看到春菜角色

---

## 基本設定

前往 **設定** → **MP Ukagaka** → **通用設定**

### 顯示設定

| 設定項目 | 說明 |
|---------|------|
| 預設春菜 | 選擇預設顯示的角色 |
| 預設顯示春菜 | 是否預設顯示角色圖片 |
| 預設顯示對話框 | 是否預設顯示對話框 |

### 對話設定

| 設定項目 | 說明 |
|---------|------|
| 預設會話 | 「隨機吐槽」或「第一條吐槽」 |
| 會話順序 | 點擊時的下一條對話是「順序」還是「隨機」 |
| 點擊春菜 | 點擊角色時的行為（顯示下一條或無操作） |

### 自動對話

| 設定項目 | 說明 |
|---------|------|
| 啟用自動對話功能 | 是否自動輪換顯示對話 |
| 自動對話間隔時間 | 每次自動換話的間隔（3-30 秒） |
| 打字效果速度 | 對話打字動畫速度（10-200 毫秒/字） |

### 外部對話檔案

| 設定項目 | 說明 |
|---------|------|
| 外部對話文件格式 | 選擇 TXT 或 JSON 格式 |
| 使用外部對話文件 | 是否從 `dialogs/` 資料夾讀取對話 |

### 頁面排除

在「不在以下頁面顯示春菜」文字框中，輸入不想顯示春菜的頁面 URL，每行一條。

支援模糊匹配：在網址尾部加入 `(*)` 可匹配所有子頁面。

**範例：**
```
/admin/
/wp-admin/(*)
/private-page/
```

---

## 春菜管理

### 查看現有春菜

前往 **設定** → **MP Ukagaka** → **春菜們**

在此頁面可以：
- 查看所有已創建的春菜
- 編輯春菜的名稱、圖片、對話
- 刪除非預設的春菜
- 設定是否顯示（可顯示勾選框）

### 創建新春菜

前往 **設定** → **MP Ukagaka** → **創建新春菜**

#### 必填欄位

| 欄位 | 說明 | 範例 |
|-----|------|------|
| 名稱 | 春菜的名字 | `芙莉蓮` |
| 圖片 | 春菜圖片的完整 URL | `https://example.com/ukagaka.png` |
| 吐槽 | 對話內容，每行一條 | 見下方範例 |

#### 對話內容範例

```
歡迎來到我的網站！
今天天氣真好呢～
要不要看看最新的文章？
魔法是需要時間慢慢研究的。
```

#### 選填欄位

| 欄位 | 說明 |
|-----|------|
| 對話檔案名稱 | 外部對話檔案的名稱（不含副檔名） |
| 生成對話檔案 | 勾選後會自動生成對應的對話檔案 |

### 外部對話檔案格式

#### TXT 格式

檔案位置：`wp-content/plugins/mp-ukagaka/dialogs/角色名.txt`

```
第一條對話

第二條對話

第三條對話
```

> ⚠️ 每條對話之間用**空行**分隔

#### JSON 格式

檔案位置：`wp-content/plugins/mp-ukagaka/dialogs/角色名.json`

```json
{
  "messages": [
    "第一條對話",
    "第二條對話",
    "第三條對話"
  ]
}
```

---

## 會話設定

前往 **設定** → **MP Ukagaka** → **會話**

### 固定資訊

此訊息會**附加在每條對話的後面**。

**使用場景：**
- 顯示網站公告
- 添加簽名或標語

**範例：**
```
—— 歡迎訂閱本站 RSS
```

### 通用會話

填寫後，**所有春菜都會使用這些對話**，取代各自的自訂對話。

清空此欄則恢復使用各春菜的預設對話。

---

## AI 功能設定

前往 **設定** → **MP Ukagaka** → **AI 設定**

### 啟用 AI 頁面感知

勾選「啟用頁面感知功能」即可開啟 AI 功能。

---

## LLM 功能設定（測試階段）

> ⚠️ **重要提示**：LLM 功能目前處於**測試階段（BETA）**，功能可能不穩定，請謹慎使用。

前往 **設定** → **MP Ukagaka** → **LLM 設定**

### 什麼是 LLM 功能？

LLM（Large Language Model）功能允許你使用本機或遠程的 Ollama 服務來生成對話，**完全免費**，無需 API Key。

### 前置需求

1. **安裝 Ollama**
   - 前往 [Ollama 官網](https://ollama.ai/) 下載並安裝
   - 啟動 Ollama 服務
   - 下載模型：在終端機執行 `ollama pull qwen3:8b`（或你喜歡的模型）

2. **確認 Ollama 運行**
   - 本地：訪問 `http://localhost:11434` 應該看到 "Ollama is running"
   - 遠程：確認你的 Cloudflare Tunnel 或其他隧道服務正常運行

### 基本設定

#### 1. 啟用 LLM

- 勾選「啟用 LLM (Ollama)」
- 系統會自動將 AI 提供商切換為 Ollama

#### 2. 設定端點

**本機連接：**
```
http://localhost:11434
```

**遠程連接（Cloudflare Tunnel）：**
```
https://your-domain.com
```

> 💡 插件會自動檢測連接類型（本地/遠程）並調整超時時間

#### 3. 設定模型名稱

輸入你已下載的模型名稱，例如：
- `qwen3:8b`
- `llama3.2`
- `mistral`

> 💡 在PowerShell在PowerShell使用 `ollama list` 命令查看已下載的模型

#### 4. 測試連接

點擊「測試 Ollama 連接」按鈕，確認連接正常。

### 進階設定

#### 使用 LLM 取代內建對話

啟用此選項後：
- 所有春菜對話將由 LLM 實時生成
- 不再使用預設的靜態對話列表
- 頁面感知功能將自動關閉

**使用場景：**
- 想要完全動態的對話內容
- 不需要預設的靜態對話
- 希望每次對話都不同

#### 關閉思考模式（Qwen3 等模型）

啟用此選項後：
- 關閉 Qwen3 等模型的思考行為
- 提高回應效率
- 減少回應時間

**建議：** 使用 Qwen3 或類似模型時，建議啟用此選項。

### 遠程連接設定（Cloudflare Tunnel）

#### 使用 Cloudflare Tunnel

1. **安裝 Cloudflare Tunnel**
   ```bash
   # Windows
   cloudflared.exe service install <token>
   
   # Linux/Mac
   cloudflared service install <token>
   ```

2. **確認服務運行**
   - 檢查 Cloudflare Tunnel 服務狀態
   - 確認隧道 URL（例如：`https://your-domain.com`）

3. **在插件中設定**
   - 端點：輸入 Cloudflare Tunnel 的 URL
   - 測試連接確認正常

#### 其他隧道服務

插件也支援其他隧道服務：
- **ngrok**: `https://your-subdomain.ngrok.io`
- **其他 HTTP/HTTPS 隧道服務**

### 常見問題

#### LLM 連接失敗

1. **本地連接問題**
   - 確認 Ollama 服務正在運行
   - 檢查端口是否為 11434
   - 嘗試在瀏覽器訪問 `http://localhost:11434`

2. **遠程連接問題**
   - 確認 Cloudflare Tunnel 服務正在運行
   - 檢查隧道 URL 是否正確
   - 確認網絡連接正常
   - 檢查防火牆設定

#### 回應速度慢

1. **本地連接**
   - 使用更快的模型（如 `qwen3:8b`）
   - 啟用「關閉思考模式」
   - 檢查本機資源使用情況

2. **遠程連接**
   - 遠程連接會有額外延遲（正常現象）
   - 考慮使用更快的網絡連接
   - 檢查 Cloudflare Tunnel 的延遲

#### 模型未找到

- 確認模型名稱正確（使用 `ollama list` 查看）
- 確認模型已下載（使用 `ollama pull <model>` 下載）
- 檢查模型名稱大小寫是否正確

### 注意事項

⚠️ **測試階段限制：**
- 功能可能不穩定
- 可能會有連接問題
- 回應時間可能較長
- 功能可能會在未來版本中變更

💡 **建議：**
- 先在測試環境中試用
- 定期備份設定
- 如有問題，可以切換回傳統的 AI 功能或靜態對話

---

### 選擇 AI 提供商

支援三種 AI 服務：

| 提供商 | 特點 | 取得 API Key |
|--------|------|-------------|
| Google Gemini | 快速、免費額度高 | [Google AI Studio](https://makersuite.google.com/app/apikey) |
| OpenAI | GPT 系列模型 | [OpenAI Platform](https://platform.openai.com/api-keys) |
| Claude | 進階推理能力 | [Anthropic Console](https://console.anthropic.com/) |

### AI 設定項目

| 設定項目 | 說明 | 建議值 |
|---------|------|-------|
| API Key | 對應 AI 服務的金鑰 | — |
| 模型 | AI 模型版本 | 依需求選擇 |
| 語言設定 | AI 回應的語言 | 繁體中文 |
| 人格設定 | AI 的個性描述（System Prompt） | 見下方範例 |
| AI 回應機率 | 觸發 AI 的機率（1-100%） | 10-30% |
| 觸發頁面 | 在哪些頁面觸發 AI | `is_single` |
| AI 對話文字顏色 | AI 回應的文字顏色 | `#ff6b6b` |
| AI 對話顯示時間 | AI 回應顯示多久 | 5-10 秒 |

### 人格設定範例

**傲嬌角色：**
```
你是一個傲嬌的桌面助手「春菜」。你會用簡短、帶點傲嬌的語氣評論文章內容。回應請保持在 40 字以內。
```

**魔法師角色：**
```
你是魔法使芙莉蓮，說話語氣平靜、略帶冷淡，對魔法相關話題會比較有興趣。回應保持在 50 字以內。
```

**日文角色：**
```
あなたは可愛いデスクトップマスコットです。記事について短く（40字以内）、明るくコメントしてください。
```

### 觸發頁面說明

使用 WordPress 條件標籤，可用逗號分隔多個條件：

| 標籤 | 說明 |
|-----|------|
| `is_single` | 單篇文章頁面 |
| `is_page` | 靜態頁面 |
| `is_home` | 網誌首頁 |
| `is_front_page` | 網站首頁 |
| `is_category` | 分類頁面 |
| `is_tag` | 標籤頁面 |

**範例：** `is_single,is_page` 表示在文章和頁面都觸發

### 首次訪客打招呼

啟用後，會對首次訪問的訪客顯示個性化歡迎訊息。

> 💡 搭配 Slimstat 外掛可獲得更多訪客資訊（來源、搜尋關鍵字等）

---

## 擴展功能

前往 **設定** → **MP Ukagaka** → **擴展**

### JS 區

可以添加自訂的 JavaScript 代碼，為春菜添加更多互動功能。

**範例：雙擊春菜跳轉到指定頁面**
```javascript
document.getElementById('cur_ukagaka').addEventListener('dblclick', function() {
    window.location.href = '/about/';
});
```

### 特殊代碼

在對話中可以使用特殊代碼顯示動態內容：

| 代碼 | 說明 |
|-----|------|
| `:recentpost[5]:` | 顯示最近 5 篇文章列表 |
| `:randompost[3]:` | 顯示隨機 3 篇文章 |
| `:commenters[5]:` | 顯示最近 5 位留言者 |

**對話範例：**
```
最近的文章：:recentpost[3]:
```

---

## 常見問題

### 春菜沒有顯示

1. 確認「預設顯示春菜」已勾選
2. 檢查當前頁面是否在排除列表中
3. 清除瀏覽器快取
4. 檢查是否有 JavaScript 錯誤（按 F12 查看 Console）

### AI 沒有觸發

1. 確認已啟用「頁面感知功能」
2. 檢查 API Key 是否正確
3. 確認當前頁面符合觸發條件
4. 將「AI 回應機率」暫時設為 100% 測試
5. 確認文章內容超過 500 字

### 對話顯示不正確

1. 檢查對話檔案格式是否正確
2. TXT 格式：每條對話用**空行**分隔
3. JSON 格式：確認是有效的 JSON

### AI 回應太慢

1. 嘗試切換到更快的模型（如 `gemini-2.5-flash`）
2. 縮短人格設定（System Prompt）
3. 檢查網路連線

### LLM 連接失敗

1. **本機連接**
   - 確認 Ollama 服務正在運行
   - 檢查端口是否為 11434
   - 嘗試在瀏覽器訪問 `http://localhost:11434`

2. **遠程連接**
   - 確認 Cloudflare Tunnel 服務正在運行
   - 檢查隧道 URL 是否正確
   - 確認網絡連接正常

### LLM 回應速度慢

1. 使用更快的模型（如 `qwen3:8b`）
2. 啟用「關閉思考模式」選項
3. 遠程連接會有額外延遲（正常現象）

### 如何控制 AI 成本

1. 降低「AI 回應機率」（建議 10-20%）
2. 限制「觸發頁面」（只在 `is_single` 觸發）
3. 使用較便宜的模型
4. **或使用 LLM 功能**：完全免費，無需 API Key（測試階段）

---

## 技術支援

如有問題，請：

1. 查閱本使用者指南
2. 檢查 [常見問題](#常見問題) 章節
3. 訪問 [維護者部落格](https://www.moelog.com/)

---

**Made with ❤ for WordPress**

